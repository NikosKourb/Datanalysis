
[2]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42531
           1       0.87      0.91      0.89     21537

    accuracy                           0.92     64068
   macro avg       0.91      0.92      0.92     64068
weighted avg       0.93      0.92      0.92     64068

---------------------------------------------------------------
Precision score:0.9240494474620715
Recall score:0.9064400798625621
Accuracy score:0.9240494474620715
F1 Score:0.8891824185834661
---------------------------------------------------------------
Confusion Matrix:
[[39680  2851]
 [ 2015 19522]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 100, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.0001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9253.245478153229 seconds

[2022-03-10 15:53:39.689095]
===============================================================



[3]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42602
           1       0.87      0.91      0.89     21445

    accuracy                           0.92     64047
   macro avg       0.91      0.92      0.91     64047
weighted avg       0.92      0.92      0.92     64047

---------------------------------------------------------------
Precision score:0.9234624572579512
Recall score:0.9064583819072045
Accuracy score:0.9234624572579512
F1 Score:0.888031064412974
---------------------------------------------------------------
Confusion Matrix:
[[39706  2896]
 [ 2006 19439]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9329.808730125427 seconds

[2022-03-10 18:29:52.537882]
===============================================================



[4]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42554
           1       0.88      0.91      0.89     21484

    accuracy                           0.93     64038
   macro avg       0.91      0.92      0.92     64038
weighted avg       0.93      0.93      0.93     64038

---------------------------------------------------------------
Precision score:0.9261219900683969
Recall score:0.9094675107056414
Accuracy score:0.9261219900683969
F1 Score:0.8920084914058756
---------------------------------------------------------------
Confusion Matrix:
[[39768  2786]
 [ 1945 19539]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9429.61018705368 seconds

[2022-03-10 21:07:53.161198]
===============================================================



[5]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42525
           1       0.88      0.91      0.89     21546

    accuracy                           0.93     64071
   macro avg       0.92      0.92      0.92     64071
weighted avg       0.93      0.93      0.93     64071

---------------------------------------------------------------
Precision score:0.9268779947246024
Recall score:0.9120022277917015
Accuracy score:0.9268779947246024
F1 Score:0.8934864158235761
---------------------------------------------------------------
Confusion Matrix:
[[39736  2789]
 [ 1896 19650]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9349.721683740616 seconds

[2022-03-10 23:44:31.260865]
===============================================================



[6]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42542
           1       0.87      0.91      0.89     21492

    accuracy                           0.92     64034
   macro avg       0.91      0.92      0.92     64034
weighted avg       0.93      0.92      0.92     64034

---------------------------------------------------------------
Precision score:0.9245713214854608
Recall score:0.905499720826354
Accuracy score:0.9245713214854608
F1 Score:0.8896050466264399
---------------------------------------------------------------
Confusion Matrix:
[[39743  2799]
 [ 2031 19461]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 4365.111558198929 seconds

[2022-03-11 00:58:04.361358]
===============================================================



[7]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42554
           1       0.87      0.91      0.89     21484

    accuracy                           0.93     64038
   macro avg       0.91      0.92      0.92     64038
weighted avg       0.93      0.93      0.93     64038

---------------------------------------------------------------
Precision score:0.9258252912333302
Recall score:0.9109104449823124
Accuracy score:0.9258252912333302
F1 Score:0.8917748917748918
---------------------------------------------------------------
Confusion Matrix:
[[39718  2836]
 [ 1914 19570]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5463.980788230896 seconds

[2022-03-11 02:29:59.125170]
===============================================================



[8]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42538
           1       0.87      0.91      0.89     21514

    accuracy                           0.92     64052
   macro avg       0.91      0.92      0.92     64052
weighted avg       0.92      0.92      0.92     64052

---------------------------------------------------------------
Precision score:0.9236557796790108
Recall score:0.9070837594124755
Accuracy score:0.9236557796790108
F1 Score:0.8886612021857924
---------------------------------------------------------------
Confusion Matrix:
[[39647  2891]
 [ 1999 19515]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 7084.598163843155 seconds

[2022-03-11 04:28:54.508027]
===============================================================



[9]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42577
           1       0.87      0.91      0.89     21467

    accuracy                           0.93     64044
   macro avg       0.91      0.92      0.92     64044
weighted avg       0.93      0.93      0.93     64044

---------------------------------------------------------------
Precision score:0.9260508400474674
Recall score:0.90930265057996
Accuracy score:0.9260508400474674
F1 Score:0.8918128654970761
---------------------------------------------------------------
Confusion Matrix:
[[39788  2789]
 [ 1947 19520]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5141.294590711594 seconds

[2022-03-11 05:55:25.431895]
===============================================================



[10]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42636
           1       0.87      0.91      0.89     21420

    accuracy                           0.92     64056
   macro avg       0.91      0.92      0.92     64056
weighted avg       0.93      0.92      0.92     64056

---------------------------------------------------------------
Precision score:0.9241601099038341
Recall score:0.9088235294117647
Accuracy score:0.9241601099038341
F1 Score:0.8890664961636828
---------------------------------------------------------------
Confusion Matrix:
[[39731  2905]
 [ 1953 19467]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5893.854145288467 seconds

[2022-03-11 07:34:27.639701]
===============================================================



[11]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42532
           1       0.87      0.91      0.89     21496

    accuracy                           0.92     64028
   macro avg       0.91      0.92      0.92     64028
weighted avg       0.93      0.92      0.92     64028

---------------------------------------------------------------
Precision score:0.9243455988005248
Recall score:0.9073781168589505
Accuracy score:0.9243455988005248
F1 Score:0.8895425730834131
---------------------------------------------------------------
Confusion Matrix:
[[39679  2853]
 [ 1991 19505]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 6003.425274133682 seconds

[2022-03-11 09:15:18.552409]
===============================================================



[12]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.94      0.94     42458
           1       0.88      0.91      0.89     21602

    accuracy                           0.93     64060
   macro avg       0.92      0.92      0.92     64060
weighted avg       0.93      0.93      0.93     64060

---------------------------------------------------------------
Precision score:0.9270683733999375
Recall score:0.9112119248217757
Accuracy score:0.9270683733999375
F1 Score:0.8939146230699364
---------------------------------------------------------------
Confusion Matrix:
[[39704  2754]
 [ 1918 19684]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5959.668824911118 seconds

[2022-03-11 10:55:30.792916]
===============================================================



[13]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42609
           1       0.87      0.91      0.89     21441

    accuracy                           0.93     64050
   macro avg       0.91      0.92      0.92     64050
weighted avg       0.93      0.93      0.93     64050

---------------------------------------------------------------
Precision score:0.9253239656518345
Recall score:0.908073317475864
Accuracy score:0.9253239656518345
F1 Score:0.8906067744665279
---------------------------------------------------------------
Confusion Matrix:
[[39797  2812]
 [ 1971 19470]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5974.26026558876 seconds

[2022-03-11 12:35:54.598407]
===============================================================



[14]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42548
           1       0.87      0.91      0.89     21438

    accuracy                           0.93     63986
   macro avg       0.91      0.92      0.92     63986
weighted avg       0.93      0.93      0.93     63986

---------------------------------------------------------------
Precision score:0.9254993279779952
Recall score:0.9098330068103367
Accuracy score:0.9254993279779952
F1 Score:0.8911072024122256
---------------------------------------------------------------
Confusion Matrix:
[[39714  2834]
 [ 1933 19505]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5175.543881893158 seconds

[2022-03-11 14:03:02.384465]
===============================================================



[15]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42597
           1       0.87      0.91      0.89     21429

    accuracy                           0.93     64026
   macro avg       0.91      0.92      0.92     64026
weighted avg       0.93      0.93      0.93     64026

---------------------------------------------------------------
Precision score:0.9263111860806548
Recall score:0.9104484576975127
Accuracy score:0.9263111860806548
F1 Score:0.8921304129132562
---------------------------------------------------------------
Confusion Matrix:
[[39798  2799]
 [ 1919 19510]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5235.24724149704 seconds

[2022-03-11 15:31:09.028963]
===============================================================



[16]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42595
           1       0.87      0.91      0.89     21468

    accuracy                           0.92     64063
   macro avg       0.91      0.92      0.92     64063
weighted avg       0.93      0.92      0.92     64063

---------------------------------------------------------------
Precision score:0.9238718136834054
Recall score:0.9074902179988821
Accuracy score:0.9238718136834054
F1 Score:0.8887570995187154
---------------------------------------------------------------
Confusion Matrix:
[[39704  2891]
 [ 1986 19482]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5079.668901443481 seconds

[2022-03-11 16:56:37.279378]
===============================================================



[17]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42657
           1       0.87      0.91      0.89     21427

    accuracy                           0.92     64084
   macro avg       0.91      0.92      0.92     64084
weighted avg       0.93      0.92      0.92     64084

---------------------------------------------------------------
Precision score:0.923974783097185
Recall score:0.9081999346618752
Accuracy score:0.923974783097185
F1 Score:0.8887468030690536
---------------------------------------------------------------
Confusion Matrix:
[[39752  2905]
 [ 1967 19460]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5233.296565055847 seconds

[2022-03-11 18:24:40.017632]
===============================================================



[18]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.94      0.94     42574
           1       0.88      0.91      0.89     21490

    accuracy                           0.93     64064
   macro avg       0.92      0.92      0.92     64064
weighted avg       0.93      0.93      0.93     64064

---------------------------------------------------------------
Precision score:0.9270260989010989
Recall score:0.9095858538855282
Accuracy score:0.9270260989010989
F1 Score:0.8931892435285247
---------------------------------------------------------------
Confusion Matrix:
[[39842  2732]
 [ 1943 19547]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 8902.123376369476 seconds

[2022-03-11 20:53:52.333010]
===============================================================



[19]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42492
           1       0.87      0.91      0.89     21540

    accuracy                           0.92     64032
   macro avg       0.91      0.92      0.92     64032
weighted avg       0.93      0.92      0.92     64032

---------------------------------------------------------------
Precision score:0.9243034732633684
Recall score:0.9052924791086351
Accuracy score:0.9243034732633684
F1 Score:0.8894565192601546
---------------------------------------------------------------
Confusion Matrix:
[[39685  2807]
 [ 2040 19500]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 8912.593359231949 seconds

[2022-03-11 23:23:12.284785]
===============================================================



[20]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42554
           1       0.87      0.91      0.89     21484

    accuracy                           0.93     64038
   macro avg       0.91      0.92      0.92     64038
weighted avg       0.93      0.93      0.93     64038

---------------------------------------------------------------
Precision score:0.9259033698741372
Recall score:0.9114224539191956
Accuracy score:0.9259033698741372
F1 Score:0.89193067164689
---------------------------------------------------------------
Confusion Matrix:
[[39712  2842]
 [ 1903 19581]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 8927.516828775406 seconds

[2022-03-12 01:52:48.956736]
===============================================================



[21]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42595
           1       0.87      0.91      0.89     21468

    accuracy                           0.93     64063
   macro avg       0.91      0.92      0.92     64063
weighted avg       0.93      0.93      0.93     64063

---------------------------------------------------------------
Precision score:0.926634718948535
Recall score:0.9130799329234209
Accuracy score:0.926634718948535
F1 Score:0.8929482507288629
---------------------------------------------------------------
Confusion Matrix:
[[39761  2834]
 [ 1866 19602]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9046.92139005661 seconds

[2022-03-12 04:24:25.234341]
===============================================================



[22]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42577
           1       0.87      0.92      0.89     21467

    accuracy                           0.93     64044
   macro avg       0.91      0.92      0.92     64044
weighted avg       0.93      0.93      0.93     64044

---------------------------------------------------------------
Precision score:0.9260820685778527
Recall score:0.9157311221875437
Accuracy score:0.9260820685778527
F1 Score:0.8925312145289442
---------------------------------------------------------------
Confusion Matrix:
[[39652  2925]
 [ 1809 19658]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 13431.308836698532 seconds

[2022-03-12 08:09:06.105117]
===============================================================



[23]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42554
           1       0.88      0.91      0.89     21484

    accuracy                           0.93     64038
   macro avg       0.92      0.92      0.92     64038
weighted avg       0.93      0.93      0.93     64038

---------------------------------------------------------------
Precision score:0.9270745494862426
Recall score:0.9125861105939304
Accuracy score:0.9270745494862426
F1 Score:0.8935782325327013
---------------------------------------------------------------
Confusion Matrix:
[[39762  2792]
 [ 1878 19606]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 13293.49121928215 seconds

[2022-03-12 11:51:31.803083]
===============================================================



[24]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.94      0.95     42570
           1       0.88      0.91      0.90     21470

    accuracy                           0.93     64040
   macro avg       0.92      0.92      0.92     64040
weighted avg       0.93      0.93      0.93     64040

---------------------------------------------------------------
Precision score:0.9282948157401624
Recall score:0.9141127154168608
Accuracy score:0.9282948157401624
F1 Score:0.8952650305629049
---------------------------------------------------------------
Confusion Matrix:
[[39822  2748]
 [ 1844 19626]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 13187.270992040634 seconds

[2022-03-12 15:32:10.377544]
===============================================================



[25]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.94      0.95     42530
           1       0.88      0.92      0.90     21515

    accuracy                           0.93     64045
   macro avg       0.92      0.93      0.92     64045
weighted avg       0.93      0.93      0.93     64045

---------------------------------------------------------------
Precision score:0.9296119915684284
Recall score:0.9185219614222635
Accuracy score:0.9296119915684284
F1 Score:0.8976199127906975
---------------------------------------------------------------
Confusion Matrix:
[[39775  2755]
 [ 1753 19762]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.0001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 13359.587904691696 seconds

[2022-03-12 19:15:39.236807]
===============================================================



[26]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64935
           1       0.87      0.92      0.89     51555

    accuracy                           0.90    116490
   macro avg       0.90      0.90      0.90    116490
weighted avg       0.90      0.90      0.90    116490

---------------------------------------------------------------
Precision score:0.9029015366125848
Recall score:0.9201047425080011
Accuracy score:0.9029015366125848
F1 Score:0.8934763568556171
---------------------------------------------------------------
Confusion Matrix:
[[57743  7192]
 [ 4119 47436]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 20205.429086446762 seconds

[2022-03-13 00:52:51.964579]
===============================================================



[27]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64792
           1       0.87      0.92      0.89     51702

    accuracy                           0.90    116494
   macro avg       0.90      0.90      0.90    116494
weighted avg       0.90      0.90      0.90    116494

---------------------------------------------------------------
Precision score:0.9006815801672189
Recall score:0.9169084368109551
Accuracy score:0.9006815801672189
F1 Score:0.8912409994171947
---------------------------------------------------------------
Confusion Matrix:
[[57518  7274]
 [ 4296 47406]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 19620.109153032303 seconds

[2022-03-13 06:20:17.091028]
===============================================================



[28]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64797
           1       0.87      0.92      0.89     51581

    accuracy                           0.90    116378
   macro avg       0.90      0.90      0.90    116378
weighted avg       0.90      0.90      0.90    116378

---------------------------------------------------------------
Precision score:0.9007114746773445
Recall score:0.9173920629689226
Accuracy score:0.9007114746773445
F1 Score:0.8911907340270258
---------------------------------------------------------------
Confusion Matrix:
[[57503  7294]
 [ 4261 47320]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 19770.726132154465 seconds

[2022-03-13 11:50:14.209535]
===============================================================



[29]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64796
           1       0.87      0.92      0.89     51583

    accuracy                           0.90    116379
   macro avg       0.90      0.90      0.90    116379
weighted avg       0.90      0.90      0.90    116379

---------------------------------------------------------------
Precision score:0.9007037352099606
Recall score:0.9151852354457864
Accuracy score:0.9007037352099606
F1 Score:0.8909523270297814
---------------------------------------------------------------
Confusion Matrix:
[[57615  7181]
 [ 4375 47208]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 19627.936166524887 seconds

[2022-03-13 17:17:49.147474]
===============================================================



[30]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.88      0.91     64752
           1       0.86      0.92      0.89     51573

    accuracy                           0.90    116325
   macro avg       0.90      0.90      0.90    116325
weighted avg       0.90      0.90      0.90    116325

---------------------------------------------------------------
Precision score:0.8994025359982807
Recall score:0.9186008182576154
Accuracy score:0.8994025359982807
F1 Score:0.8900725209484086
---------------------------------------------------------------
Confusion Matrix:
[[57248  7504]
 [ 4198 47375]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9935.36565065384 seconds

[2022-03-13 20:03:51.046176]
===============================================================



[31]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64862
           1       0.86      0.91      0.89     51657

    accuracy                           0.90    116519
   macro avg       0.90      0.90      0.90    116519
weighted avg       0.90      0.90      0.90    116519

---------------------------------------------------------------
Precision score:0.8981110376848411
Recall score:0.91275141800724
Accuracy score:0.8981110376848411
F1 Score:0.8881814414346533
---------------------------------------------------------------
Confusion Matrix:
[[57497  7365]
 [ 4507 47150]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11077.180463314056 seconds

[2022-03-13 23:08:54.603370]
===============================================================



[32]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64771
           1       0.87      0.92      0.89     51617

    accuracy                           0.90    116388
   macro avg       0.90      0.90      0.90    116388
weighted avg       0.90      0.90      0.90    116388

---------------------------------------------------------------
Precision score:0.8995944599099563
Recall score:0.9158610535288761
Accuracy score:0.8995944599099563
F1 Score:0.8899975525726228
---------------------------------------------------------------
Confusion Matrix:
[[57428  7343]
 [ 4343 47274]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 10488.849016904831 seconds

[2022-03-14 02:04:08.891556]
===============================================================



[33]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64778
           1       0.87      0.92      0.89     51692

    accuracy                           0.90    116470
   macro avg       0.90      0.90      0.90    116470
weighted avg       0.90      0.90      0.90    116470

---------------------------------------------------------------
Precision score:0.901004550528033
Recall score:0.9169117078077845
Accuracy score:0.901004550528033
F1 Score:0.8915578796884993
---------------------------------------------------------------
Confusion Matrix:
[[57543  7235]
 [ 4295 47397]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 12589.337057352066 seconds

[2022-03-14 05:34:25.310631]
===============================================================



[34]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64795
           1       0.87      0.91      0.89     51664

    accuracy                           0.90    116459
   macro avg       0.90      0.90      0.90    116459
weighted avg       0.90      0.90      0.90    116459

---------------------------------------------------------------
Precision score:0.8987626546681665
Recall score:0.9107502322700527
Accuracy score:0.8987626546681665
F1 Score:0.8886643499282314
---------------------------------------------------------------
Confusion Matrix:
[[57616  7179]
 [ 4611 47053]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11205.67683005333 seconds

[2022-03-14 08:41:38.339359]
===============================================================



[35]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64904
           1       0.87      0.92      0.89     51491

    accuracy                           0.90    116395
   macro avg       0.90      0.90      0.90    116395
weighted avg       0.90      0.90      0.90    116395

---------------------------------------------------------------
Precision score:0.9006142875553074
Recall score:0.9162572099978638
Accuracy score:0.9006142875553074
F1 Score:0.8907916847610596
---------------------------------------------------------------
Confusion Matrix:
[[57648  7256]
 [ 4312 47179]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11171.22956252098 seconds

[2022-03-14 11:48:17.101988]
===============================================================



[36]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64731
           1       0.87      0.91      0.89     51764

    accuracy                           0.90    116495
   macro avg       0.90      0.90      0.90    116495
weighted avg       0.90      0.90      0.90    116495

---------------------------------------------------------------
Precision score:0.9007596892570496
Recall score:0.9140908739664632
Accuracy score:0.9007596892570496
F1 Score:0.8911342341918169
---------------------------------------------------------------
Confusion Matrix:
[[57617  7114]
 [ 4447 47317]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11458.481626749039 seconds

[2022-03-14 14:59:41.944720]
===============================================================



[37]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64783
           1       0.87      0.91      0.89     51598

    accuracy                           0.90    116381
   macro avg       0.90      0.90      0.90    116381
weighted avg       0.90      0.90      0.90    116381

---------------------------------------------------------------
Precision score:0.898600286988426
Recall score:0.9129036009147642
Accuracy score:0.898600286988426
F1 Score:0.8886792630814364
---------------------------------------------------------------
Confusion Matrix:
[[57476  7307]
 [ 4494 47104]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11574.846066236496 seconds

[2022-03-14 18:13:05.495812]
===============================================================



[38]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64837
           1       0.87      0.92      0.89     51527

    accuracy                           0.90    116364
   macro avg       0.90      0.90      0.90    116364
weighted avg       0.90      0.90      0.90    116364

---------------------------------------------------------------
Precision score:0.9007854662954178
Recall score:0.9174995633357269
Accuracy score:0.9007854662954178
F1 Score:0.891184482124848
---------------------------------------------------------------
Confusion Matrix:
[[57543  7294]
 [ 4251 47276]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'saga', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11192.751536369324 seconds

[2022-03-14 21:20:05.829458]
===============================================================



[39]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.88      0.91     64863
           1       0.86      0.92      0.89     51558

    accuracy                           0.90    116421
   macro avg       0.90      0.90      0.90    116421
weighted avg       0.90      0.90      0.90    116421

---------------------------------------------------------------
Precision score:0.8978191219797116
Recall score:0.9165018037937857
Accuracy score:0.8978191219797116
F1 Score:0.8881975902708595
---------------------------------------------------------------
Confusion Matrix:
[[57272  7591]
 [ 4305 47253]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11246.019232034683 seconds

[2022-03-15 00:28:00.241188]
===============================================================



[40]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64819
           1       0.87      0.92      0.89     51658

    accuracy                           0.90    116477
   macro avg       0.90      0.90      0.90    116477
weighted avg       0.90      0.90      0.90    116477

---------------------------------------------------------------
Precision score:0.9020235754698352
Recall score:0.9201478957760657
Accuracy score:0.9020235754698352
F1 Score:0.8928229305584252
---------------------------------------------------------------
Confusion Matrix:
[[57532  7287]
 [ 4125 47533]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11165.399440288544 seconds

[2022-03-15 03:34:32.586056]
===============================================================



[41]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64756
           1       0.87      0.91      0.89     51737

    accuracy                           0.90    116493
   macro avg       0.90      0.90      0.90    116493
weighted avg       0.90      0.90      0.90    116493

---------------------------------------------------------------
Precision score:0.8990325598963028
Recall score:0.9140653690782226
Accuracy score:0.8990325598963028
F1 Score:0.8893966749416987
---------------------------------------------------------------
Confusion Matrix:
[[57440  7316]
 [ 4446 47291]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.001, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11305.35212802887 seconds

[2022-03-15 06:43:25.143095]
===============================================================



[42]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64793
           1       0.87      0.91      0.89     51562

    accuracy                           0.90    116355
   macro avg       0.90      0.90      0.90    116355
weighted avg       0.90      0.90      0.90    116355

---------------------------------------------------------------
Precision score:0.8997378711701259
Recall score:0.914277956634731
Accuracy score:0.8997378711701259
F1 Score:0.8898914582350165
---------------------------------------------------------------
Confusion Matrix:
[[57547  7246]
 [ 4420 47142]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 18597.27752804756 seconds

[2022-03-15 11:53:48.781235]
===============================================================



[43]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64780
           1       0.87      0.91      0.89     51587

    accuracy                           0.90    116367
   macro avg       0.90      0.90      0.90    116367
weighted avg       0.90      0.90      0.90    116367

---------------------------------------------------------------
Precision score:0.8993357223267765
Recall score:0.9148622715025103
Accuracy score:0.8993357223267765
F1 Score:0.8895988841136997
---------------------------------------------------------------
Confusion Matrix:
[[57458  7322]
 [ 4392 47195]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 18821.367255926132 seconds

[2022-03-15 17:07:56.697118]
===============================================================



[44]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64863
           1       0.87      0.92      0.89     51557

    accuracy                           0.90    116420
   macro avg       0.90      0.90      0.90    116420
weighted avg       0.90      0.90      0.90    116420

---------------------------------------------------------------
Precision score:0.9004466586497165
Recall score:0.9181876369843086
Accuracy score:0.9004466586497165
F1 Score:0.8909361237625626
---------------------------------------------------------------
Confusion Matrix:
[[57491  7372]
 [ 4218 47339]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 18523.280469179153 seconds

[2022-03-15 22:17:09.139909]
===============================================================



[45]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64750
           1       0.87      0.91      0.89     51680

    accuracy                           0.90    116430
   macro avg       0.90      0.90      0.90    116430
weighted avg       0.90      0.90      0.90    116430

---------------------------------------------------------------
Precision score:0.9007472300953363
Recall score:0.9142414860681115
Accuracy score:0.9007472300953363
F1 Score:0.8910345868064723
---------------------------------------------------------------
Confusion Matrix:
[[57626  7124]
 [ 4432 47248]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 18722.033195257187 seconds

[2022-03-16 03:29:37.940496]
===============================================================



[46]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64792
           1       0.87      0.93      0.90     51609

    accuracy                           0.91    116401
   macro avg       0.90      0.91      0.90    116401
weighted avg       0.91      0.91      0.91    116401

---------------------------------------------------------------
Precision score:0.9053015008462126
Recall score:0.925419984886357
Accuracy score:0.9053015008462126
F1 Score:0.8965394253963188
---------------------------------------------------------------
Confusion Matrix:
[[57618  7174]
 [ 3849 47760]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 27496.2370326519 seconds

[2022-03-16 11:08:21.139776]
===============================================================



[47]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64837
           1       0.87      0.92      0.90     51670

    accuracy                           0.91    116507
   macro avg       0.90      0.91      0.91    116507
weighted avg       0.91      0.91      0.91    116507

---------------------------------------------------------------
Precision score:0.9063403915644553
Recall score:0.9230114186181537
Accuracy score:0.9063403915644553
F1 Score:0.8973432678557989
---------------------------------------------------------------
Confusion Matrix:
[[57903  6934]
 [ 3978 47692]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 100, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 27529.764036417007 seconds

[2022-03-16 18:47:37.624189]
===============================================================



[48]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64780
           1       0.87      0.93      0.90     51566

    accuracy                           0.91    116346
   macro avg       0.90      0.91      0.91    116346
weighted avg       0.91      0.91      0.91    116346

---------------------------------------------------------------
Precision score:0.9059185532807316
Recall score:0.925125082418648
Accuracy score:0.9059185532807316
F1 Score:0.8970814998683667
---------------------------------------------------------------
Confusion Matrix:
[[57695  7085]
 [ 3861 47705]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 100, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 27116.631018400192 seconds

[2022-03-17 02:20:01.038229]
===============================================================



[49]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64898
           1       0.87      0.92      0.90     51479

    accuracy                           0.90    116377
   macro avg       0.90      0.91      0.90    116377
weighted avg       0.91      0.90      0.91    116377

---------------------------------------------------------------
Precision score:0.9048609261280149
Recall score:0.9229588764350511
Accuracy score:0.9048609261280149
F1 Score:0.895643650210183
---------------------------------------------------------------
Confusion Matrix:
[[57792  7106]
 [ 3966 47513]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 26864.11636352539 seconds

[2022-03-17 09:48:12.718932]
===============================================================



[50]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42570
           1       0.87      0.91      0.89     21470

    accuracy                           0.93     64040
   macro avg       0.91      0.92      0.92     64040
weighted avg       0.93      0.93      0.93     64040

---------------------------------------------------------------
Precision score:0.9257651467832605
Recall score:0.9101071262226362
Accuracy score:0.9257651467832605
F1 Score:0.8915453757357303
---------------------------------------------------------------
Confusion Matrix:
[[39746  2824]
 [ 1930 19540]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'liblinear', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 10208.949478626251 seconds

[2022-03-17 15:56:27.682876]
===============================================================



[51]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42497
           1       0.87      0.91      0.89     21577

    accuracy                           0.92     64074
   macro avg       0.91      0.92      0.92     64074
weighted avg       0.93      0.92      0.93     64074

---------------------------------------------------------------
Precision score:0.9248525142803633
Recall score:0.9078185104509431
Accuracy score:0.9248525142803633
F1 Score:0.8905457934577526
---------------------------------------------------------------
Confusion Matrix:
[[39671  2826]
 [ 1989 19588]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 7698.792307853699 seconds

[2022-03-17 18:05:37.728927]
===============================================================



[52]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42551
           1       0.88      0.91      0.89     21491

    accuracy                           0.93     64042
   macro avg       0.92      0.92      0.92     64042
weighted avg       0.93      0.93      0.93     64042

---------------------------------------------------------------
Precision score:0.9271259485962338
Recall score:0.9128937694849006
Accuracy score:0.9271259485962338
F1 Score:0.8937023118095889
---------------------------------------------------------------
Confusion Matrix:
[[39756  2795]
 [ 1872 19619]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 6244.327255249023 seconds

[2022-03-17 19:50:34.311836]
===============================================================



[53]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42520
           1       0.87      0.91      0.89     21539

    accuracy                           0.92     64059
   macro avg       0.91      0.92      0.92     64059
weighted avg       0.93      0.92      0.93     64059

---------------------------------------------------------------
Precision score:0.9249598026819026
Recall score:0.9066344769952179
Accuracy score:0.9249598026819026
F1 Score:0.8904087727697604
---------------------------------------------------------------
Confusion Matrix:
[[39724  2796]
 [ 2011 19528]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 5296.44352555275 seconds

[2022-03-17 21:19:42.038353]
===============================================================



[54]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42531
           1       0.87      0.92      0.89     21537

    accuracy                           0.93     64068
   macro avg       0.91      0.93      0.92     64068
weighted avg       0.93      0.93      0.93     64068

---------------------------------------------------------------
Precision score:0.9267653118561529
Recall score:0.9203695965083345
Accuracy score:0.9267653118561529
F1 Score:0.8941717791411044
---------------------------------------------------------------
Confusion Matrix:
[[39554  2977]
 [ 1715 19822]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 9563.675743818283 seconds

[2022-03-17 23:59:56.145696]
===============================================================



[55]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42518
           1       0.87      0.91      0.89     21511

    accuracy                           0.93     64029
   macro avg       0.91      0.92      0.92     64029
weighted avg       0.93      0.93      0.93     64029

---------------------------------------------------------------
Precision score:0.9255962142154336
Recall score:0.9134861233787365
Accuracy score:0.9255962142154336
F1 Score:0.8918845315904139
---------------------------------------------------------------
Confusion Matrix:
[[39615  2903]
 [ 1861 19650]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 14264.10706114769 seconds

[2022-03-18 03:58:28.800624]
===============================================================



[56]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64892
           1       0.87      0.92      0.89     51638

    accuracy                           0.90    116530
   macro avg       0.90      0.90      0.90    116530
weighted avg       0.90      0.90      0.90    116530

---------------------------------------------------------------
Precision score:0.9018192740066936
Recall score:0.9196521941206088
Accuracy score:0.9018192740066936
F1 Score:0.8924910025465377
---------------------------------------------------------------
Confusion Matrix:
[[57600  7292]
 [ 4149 47489]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.005, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 20856.268029928207 seconds

[2022-03-18 09:46:32.858424]
===============================================================



[57]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64783
           1       0.87      0.92      0.89     51619

    accuracy                           0.90    116402
   macro avg       0.90      0.90      0.90    116402
weighted avg       0.90      0.90      0.90    116402

---------------------------------------------------------------
Precision score:0.9016769471314926
Recall score:0.9167554582614929
Accuracy score:0.9016769471314926
F1 Score:0.8921188813166304
---------------------------------------------------------------
Confusion Matrix:
[[57635  7148]
 [ 4297 47322]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 75, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11000.346863031387 seconds

[2022-03-18 12:50:22.124611]
===============================================================



[58]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     64802
           1       0.86      0.92      0.89     51636

    accuracy                           0.90    116438
   macro avg       0.90      0.90      0.90    116438
weighted avg       0.90      0.90      0.90    116438

---------------------------------------------------------------
Precision score:0.9012349920129168
Recall score:0.9233093190797118
Accuracy score:0.9012349920129168
F1 Score:0.8923744993074534
---------------------------------------------------------------
Confusion Matrix:
[[57262  7540]
 [ 3960 47676]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11595.589151859283 seconds

[2022-03-18 16:04:05.447065]
===============================================================



[59]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64807
           1       0.87      0.91      0.89     51596

    accuracy                           0.90    116403
   macro avg       0.90      0.90      0.90    116403
weighted avg       0.90      0.90      0.90    116403

---------------------------------------------------------------
Precision score:0.8988342224856748
Recall score:0.9143344445305838
Accuracy score:0.8988342224856748
F1 Score:0.8890396502336801
---------------------------------------------------------------
Confusion Matrix:
[[57451  7356]
 [ 4420 47176]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 11355.129851818085 seconds

[2022-03-18 19:13:49.367094]
===============================================================



[60]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64837
           1       0.87      0.91      0.89     51527

    accuracy                           0.90    116364
   macro avg       0.90      0.90      0.90    116364
weighted avg       0.90      0.90      0.90    116364

---------------------------------------------------------------
Precision score:0.8994362517617133
Recall score:0.9147049119878898
Accuracy score:0.8994362517617133
F1 Score:0.8895683521129418
---------------------------------------------------------------
Confusion Matrix:
[[57530  7307]
 [ 4395 47132]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.01, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 19609.492836475372 seconds

[2022-03-19 00:41:07.986364]
===============================================================



[61]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.005, 0.01], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 75, 100], 'multi_class': ['auto', 'ovr', 'multinomial'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'random_state': [42], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'tol': [0.01, 0.001, 0.0001], 'verbose': [0], 'warm_start': [True, False]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.92     64845
           1       0.87      0.93      0.90     51580

    accuracy                           0.91    116425
   macro avg       0.91      0.91      0.91    116425
weighted avg       0.91      0.91      0.91    116425

---------------------------------------------------------------
Precision score:0.9082327678763152
Recall score:0.9295075610701823
Accuracy score:0.9082327678763152
F1 Score:0.8997485268175506
---------------------------------------------------------------
Confusion Matrix:
[[57797  7048]
 [ 3636 47944]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'newton-cg', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 28447.028886318207 seconds

[2022-03-19 08:35:44.476558]
===============================================================



[62]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42497
           1       0.87      0.92      0.89     21577

    accuracy                           0.93     64074
   macro avg       0.91      0.92      0.92     64074
weighted avg       0.93      0.93      0.93     64074

---------------------------------------------------------------
Precision score:0.9256796828666854
Recall score:0.9158826528247671
Accuracy score:0.9256796828666854
F1 Score:0.8924716614731518
---------------------------------------------------------------
Confusion Matrix:
[[39550  2947]
 [ 1815 19762]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 161.63576364517212 seconds

[2022-03-19 13:49:05.475420]
===============================================================



[63]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42528
           1       0.87      0.91      0.89     21523

    accuracy                           0.92     64051
   macro avg       0.91      0.92      0.91     64051
weighted avg       0.92      0.92      0.92     64051

---------------------------------------------------------------
Precision score:0.922577321197171
Recall score:0.9087023184500302
Accuracy score:0.922577321197171
F1 Score:0.8874872376630742
---------------------------------------------------------------
Confusion Matrix:
[[39534  2994]
 [ 1965 19558]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 124.71919226646423 seconds

[2022-03-19 13:52:01.966343]
===============================================================



[64]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.92      0.94     42520
           1       0.86      0.92      0.89     21539

    accuracy                           0.92     64059
   macro avg       0.91      0.92      0.92     64059
weighted avg       0.93      0.92      0.92     64059

---------------------------------------------------------------
Precision score:0.9234299630028567
Recall score:0.9211198291471284
Accuracy score:0.9234299630028567
F1 Score:0.889985421105753
---------------------------------------------------------------
Confusion Matrix:
[[39314  3206]
 [ 1699 19840]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 141.2242021560669 seconds

[2022-03-19 13:55:10.959298]
===============================================================



[65]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42602
           1       0.87      0.91      0.89     21445

    accuracy                           0.92     64047
   macro avg       0.91      0.92      0.91     64047
weighted avg       0.92      0.92      0.92     64047

---------------------------------------------------------------
Precision score:0.9233687760550845
Recall score:0.9093494987176498
Accuracy score:0.9233687760550845
F1 Score:0.8882259166476885
---------------------------------------------------------------
Confusion Matrix:
[[39638  2964]
 [ 1944 19501]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 132.6169593334198 seconds

[2022-03-19 13:58:12.587412]
===============================================================



[66]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42531
           1       0.87      0.91      0.89     21537

    accuracy                           0.92     64068
   macro avg       0.91      0.92      0.92     64068
weighted avg       0.93      0.92      0.92     64068

---------------------------------------------------------------
Precision score:0.923924580133608
Recall score:0.9096438686910897
Accuracy score:0.923924580133608
F1 Score:0.8893680769929181
---------------------------------------------------------------
Confusion Matrix:
[[39603  2928]
 [ 1946 19591]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 153.1482434272766 seconds

[2022-03-19 14:01:33.899900]
===============================================================



[67]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42518
           1       0.87      0.92      0.89     21511

    accuracy                           0.93     64029
   macro avg       0.91      0.92      0.92     64029
weighted avg       0.93      0.93      0.93     64029

---------------------------------------------------------------
Precision score:0.9260491339861625
Recall score:0.9159499790804705
Accuracy score:0.9260491339861625
F1 Score:0.8927301148592013
---------------------------------------------------------------
Confusion Matrix:
[[39591  2927]
 [ 1808 19703]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 199.53405380249023 seconds

[2022-03-19 14:05:42.624391]
===============================================================



[68]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64767
           1       0.87      0.91      0.89     51694

    accuracy                           0.90    116461
   macro avg       0.90      0.90      0.90    116461
weighted avg       0.90      0.90      0.90    116461

---------------------------------------------------------------
Precision score:0.8997346751272959
Recall score:0.9132201029132975
Accuracy score:0.8997346751272959
F1 Score:0.8899361880614178
---------------------------------------------------------------
Confusion Matrix:
[[57576  7191]
 [ 4486 47208]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 284.94001269340515 seconds

[2022-03-19 14:10:54.497463]
===============================================================



[69]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64745
           1       0.87      0.92      0.89     51576

    accuracy                           0.90    116321
   macro avg       0.90      0.90      0.90    116321
weighted avg       0.90      0.90      0.90    116321

---------------------------------------------------------------
Precision score:0.9000868286895746
Recall score:0.9158329455560726
Accuracy score:0.9000868286895746
F1 Score:0.890453568600837
---------------------------------------------------------------
Confusion Matrix:
[[57464  7281]
 [ 4341 47235]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 237.31228303909302 seconds

[2022-03-19 14:15:20.581203]
===============================================================



[70]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64750
           1       0.87      0.91      0.89     51584

    accuracy                           0.90    116334
   macro avg       0.90      0.90      0.90    116334
weighted avg       0.90      0.90      0.90    116334

---------------------------------------------------------------
Precision score:0.8982326748843846
Recall score:0.911232165012407
Accuracy score:0.8982326748843846
F1 Score:0.8881519900991035
---------------------------------------------------------------
Confusion Matrix:
[[57490  7260]
 [ 4579 47005]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 267.33019399642944 seconds

[2022-03-19 14:20:16.169764]
===============================================================



[71]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64845
           1       0.87      0.91      0.89     51698

    accuracy                           0.90    116543
   macro avg       0.90      0.90      0.90    116543
weighted avg       0.90      0.90      0.90    116543

---------------------------------------------------------------
Precision score:0.8985095629939164
Recall score:0.9116406824248521
Accuracy score:0.8985095629939164
F1 Score:0.8885076540230752
---------------------------------------------------------------
Confusion Matrix:
[[57585  7260]
 [ 4568 47130]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 257.5370955467224 seconds

[2022-03-19 14:24:59.749705]
===============================================================



[72]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64869
           1       0.87      0.92      0.89     51564

    accuracy                           0.90    116433
   macro avg       0.90      0.90      0.90    116433
weighted avg       0.90      0.90      0.90    116433

---------------------------------------------------------------
Precision score:0.9002860013913582
Recall score:0.9173648281746956
Accuracy score:0.9002860013913582
F1 Score:0.8906944339835806
---------------------------------------------------------------
Confusion Matrix:
[[57520  7349]
 [ 4261 47303]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 276.48358726501465 seconds

[2022-03-19 14:30:04.314098]
===============================================================



[73]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64771
           1       0.87      0.92      0.90     51713

    accuracy                           0.91    116484
   macro avg       0.90      0.91      0.91    116484
weighted avg       0.91      0.91      0.91    116484

---------------------------------------------------------------
Precision score:0.9058669001751314
Recall score:0.9234428480266084
Accuracy score:0.9058669001751314
F1 Score:0.8970161449381534
---------------------------------------------------------------
Confusion Matrix:
[[57765  7006]
 [ 3959 47754]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 386.6254277229309 seconds

[2022-03-19 14:36:58.914102]
===============================================================



[74]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42474
           1       0.87      0.91      0.89     21565

    accuracy                           0.92     64039
   macro avg       0.91      0.92      0.92     64039
weighted avg       0.93      0.92      0.92     64039

---------------------------------------------------------------
Precision score:0.9242961320445353
Recall score:0.9093902156271737
Accuracy score:0.9242961320445353
F1 Score:0.88999319264806
---------------------------------------------------------------
Confusion Matrix:
[[39580  2894]
 [ 1954 19611]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 154.58687496185303 seconds

[2022-03-19 15:12:57.501401]
===============================================================



[75]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42602
           1       0.87      0.91      0.89     21445

    accuracy                           0.92     64047
   macro avg       0.91      0.92      0.92     64047
weighted avg       0.93      0.92      0.92     64047

---------------------------------------------------------------
Precision score:0.9236966602651178
Recall score:0.9094893914665423
Accuracy score:0.9236966602651178
F1 Score:0.8886661350951133
---------------------------------------------------------------
Confusion Matrix:
[[39656  2946]
 [ 1941 19504]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 160.13010382652283 seconds

[2022-03-19 15:16:28.599098]
===============================================================



[76]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42525
           1       0.87      0.91      0.89     21550

    accuracy                           0.93     64075
   macro avg       0.91      0.92      0.92     64075
weighted avg       0.93      0.93      0.93     64075

---------------------------------------------------------------
Precision score:0.9253999219664456
Recall score:0.914245939675174
Accuracy score:0.9253999219664456
F1 Score:0.8918160420061559
---------------------------------------------------------------
Confusion Matrix:
[[39593  2932]
 [ 1848 19702]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 159.64569926261902 seconds

[2022-03-19 15:19:55.480013]
===============================================================



[77]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42530
           1       0.87      0.92      0.89     21515

    accuracy                           0.93     64045
   macro avg       0.91      0.92      0.92     64045
weighted avg       0.93      0.93      0.93     64045

---------------------------------------------------------------
Precision score:0.9262081349051449
Recall score:0.91508250058099
Accuracy score:0.9262081349051449
F1 Score:0.8928393270146479
---------------------------------------------------------------
Confusion Matrix:
[[39631  2899]
 [ 1827 19688]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 162.58969354629517 seconds

[2022-03-19 15:23:29.166453]
===============================================================



[78]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42528
           1       0.87      0.91      0.89     21523

    accuracy                           0.93     64051
   macro avg       0.91      0.92      0.92     64051
weighted avg       0.93      0.93      0.93     64051

---------------------------------------------------------------
Precision score:0.9252626813008384
Recall score:0.9121869627839985
Accuracy score:0.9252626813008384
F1 Score:0.8913354368601457
---------------------------------------------------------------
Confusion Matrix:
[[39631  2897]
 [ 1890 19633]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 120.69356775283813 seconds

[2022-03-19 15:26:20.924385]
===============================================================



[79]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42512
           1       0.87      0.91      0.89     21542

    accuracy                           0.92     64054
   macro avg       0.91      0.92      0.92     64054
weighted avg       0.93      0.92      0.92     64054

---------------------------------------------------------------
Precision score:0.924438754800637
Recall score:0.9079472658063318
Accuracy score:0.924438754800637
F1 Score:0.8898948996769643
---------------------------------------------------------------
Confusion Matrix:
[[39655  2857]
 [ 1983 19559]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 121.27069401741028 seconds

[2022-03-19 15:29:11.886216]
===============================================================



[80]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42595
           1       0.87      0.91      0.89     21468

    accuracy                           0.92     64063
   macro avg       0.91      0.92      0.92     64063
weighted avg       0.93      0.92      0.93     64063

---------------------------------------------------------------
Precision score:0.9248864399107128
Recall score:0.9113564374883547
Accuracy score:0.9248864399107128
F1 Score:0.8904920121978973
---------------------------------------------------------------
Confusion Matrix:
[[39686  2909]
 [ 1903 19565]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 120.16003227233887 seconds

[2022-03-19 15:32:02.667783]
===============================================================



[81]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42570
           1       0.88      0.91      0.89     21470

    accuracy                           0.93     64040
   macro avg       0.91      0.92      0.92     64040
weighted avg       0.93      0.93      0.93     64040

---------------------------------------------------------------
Precision score:0.9267645221736415
Recall score:0.9109455053563111
Accuracy score:0.9267645221736415
F1 Score:0.8929370405880473
---------------------------------------------------------------
Confusion Matrix:
[[39792  2778]
 [ 1912 19558]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 120.90450763702393 seconds

[2022-03-19 15:34:50.201943]
===============================================================



[82]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42595
           1       0.87      0.92      0.89     21468

    accuracy                           0.93     64063
   macro avg       0.91      0.92      0.92     64063
weighted avg       0.93      0.93      0.93     64063

---------------------------------------------------------------
Precision score:0.9252298518645709
Recall score:0.9191354574250047
Accuracy score:0.9252298518645709
F1 Score:0.8917611967279794
---------------------------------------------------------------
Confusion Matrix:
[[39541  3054]
 [ 1736 19732]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 141.8045015335083 seconds

[2022-03-19 15:38:02.620552]
===============================================================



[83]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42597
           1       0.87      0.92      0.89     21456

    accuracy                           0.93     64053
   macro avg       0.91      0.92      0.92     64053
weighted avg       0.93      0.93      0.93     64053

---------------------------------------------------------------
Precision score:0.9267949978923704
Recall score:0.9159675615212528
Accuracy score:0.9267949978923704
F1 Score:0.893419706784862
---------------------------------------------------------------
Confusion Matrix:
[[39711  2886]
 [ 1803 19653]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 139.9809594154358 seconds

[2022-03-19 15:41:11.078446]
===============================================================



[84]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42559
           1       0.86      0.92      0.89     21511

    accuracy                           0.92     64070
   macro avg       0.91      0.92      0.92     64070
weighted avg       0.93      0.92      0.93     64070

---------------------------------------------------------------
Precision score:0.9245200561885438
Recall score:0.9189252010599228
Accuracy score:0.9245200561885438
F1 Score:0.8910074374577417
---------------------------------------------------------------
Confusion Matrix:
[[39467  3092]
 [ 1744 19767]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 144.95232796669006 seconds

[2022-03-19 15:44:27.554835]
===============================================================



[85]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42563
           1       0.87      0.92      0.89     21506

    accuracy                           0.93     64069
   macro avg       0.91      0.93      0.92     64069
weighted avg       0.93      0.93      0.93     64069

---------------------------------------------------------------
Precision score:0.9264074669496949
Recall score:0.9235562168697108
Accuracy score:0.9264074669496949
F1 Score:0.8938995026890795
---------------------------------------------------------------
Confusion Matrix:
[[39492  3071]
 [ 1644 19862]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 138.66268587112427 seconds

[2022-03-19 15:47:33.100850]
===============================================================



[86]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42597
           1       0.87      0.91      0.89     21429

    accuracy                           0.93     64026
   macro avg       0.91      0.92      0.92     64026
weighted avg       0.93      0.93      0.93     64026

---------------------------------------------------------------
Precision score:0.9262643301158904
Recall score:0.9111017779644407
Accuracy score:0.9262643301158904
F1 Score:0.8921382713792868
---------------------------------------------------------------
Confusion Matrix:
[[39781  2816]
 [ 1905 19524]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 131.67778134346008 seconds

[2022-03-19 15:50:36.479942]
===============================================================



[87]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42486
           1       0.87      0.91      0.89     21576

    accuracy                           0.92     64062
   macro avg       0.91      0.92      0.92     64062
weighted avg       0.93      0.92      0.92     64062

---------------------------------------------------------------
Precision score:0.924432580937217
Recall score:0.9065628476084538
Accuracy score:0.924432580937217
F1 Score:0.889879666067651
---------------------------------------------------------------
Confusion Matrix:
[[39661  2825]
 [ 2016 19560]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 133.10390639305115 seconds

[2022-03-19 15:53:37.126264]
===============================================================



[88]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42437
           1       0.88      0.91      0.89     21600

    accuracy                           0.93     64037
   macro avg       0.91      0.92      0.92     64037
weighted avg       0.93      0.93      0.93     64037

---------------------------------------------------------------
Precision score:0.9257772850071053
Recall score:0.9080092592592592
Accuracy score:0.9257772850071053
F1 Score:0.8919256918074535
---------------------------------------------------------------
Confusion Matrix:
[[39671  2766]
 [ 1987 19613]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 130.1092450618744 seconds

[2022-03-19 15:56:38.546790]
===============================================================



[89]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42553
           1       0.87      0.91      0.89     21508

    accuracy                           0.93     64061
   macro avg       0.91      0.92      0.92     64061
weighted avg       0.93      0.93      0.93     64061

---------------------------------------------------------------
Precision score:0.9250089758199216
Recall score:0.9090570950344058
Accuracy score:0.9250089758199216
F1 Score:0.8905894142297531
---------------------------------------------------------------
Confusion Matrix:
[[39705  2848]
 [ 1956 19552]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 130.4231994152069 seconds

[2022-03-19 15:59:38.055538]
===============================================================



[90]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42528
           1       0.87      0.91      0.89     21523

    accuracy                           0.92     64051
   macro avg       0.91      0.92      0.92     64051
weighted avg       0.93      0.92      0.93     64051

---------------------------------------------------------------
Precision score:0.9246537915098906
Recall score:0.9078660038098778
Accuracy score:0.9246537915098906
F1 Score:0.8900833599052521
---------------------------------------------------------------
Confusion Matrix:
[[39685  2843]
 [ 1983 19540]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 151.2379288673401 seconds

[2022-03-19 16:03:00.960795]
===============================================================



[91]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42559
           1       0.87      0.90      0.89     21456

    accuracy                           0.92     64015
   macro avg       0.91      0.92      0.91     64015
weighted avg       0.92      0.92      0.92     64015

---------------------------------------------------------------
Precision score:0.9236585175349528
Recall score:0.9017524235645041
Accuracy score:0.9236585175349528
F1 Score:0.8878691232820136
---------------------------------------------------------------
Confusion Matrix:
[[39780  2779]
 [ 2108 19348]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 152.68063235282898 seconds

[2022-03-19 16:06:22.482745]
===============================================================



[92]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.94      0.94     42532
           1       0.88      0.91      0.89     21517

    accuracy                           0.93     64049
   macro avg       0.92      0.92      0.92     64049
weighted avg       0.93      0.93      0.93     64049

---------------------------------------------------------------
Precision score:0.9268528782650783
Recall score:0.9091416089603569
Accuracy score:0.9268528782650783
F1 Score:0.8930585039603735
---------------------------------------------------------------
Confusion Matrix:
[[39802  2730]
 [ 1955 19562]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 151.42850017547607 seconds

[2022-03-19 16:09:43.530967]
===============================================================



[93]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42594
           1       0.87      0.91      0.89     21501

    accuracy                           0.92     64095
   macro avg       0.91      0.92      0.92     64095
weighted avg       0.93      0.92      0.93     64095

---------------------------------------------------------------
Precision score:0.9247991262969031
Recall score:0.9094925817403842
Accuracy score:0.9247991262969031
F1 Score:0.8902799908946052
---------------------------------------------------------------
Confusion Matrix:
[[39720  2874]
 [ 1946 19555]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 153.67649221420288 seconds

[2022-03-19 16:13:04.966394]
===============================================================



[94]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42505
           1       0.87      0.91      0.89     21552

    accuracy                           0.93     64057
   macro avg       0.91      0.92      0.92     64057
weighted avg       0.93      0.93      0.93     64057

---------------------------------------------------------------
Precision score:0.9255350703279891
Recall score:0.9145786933927246
Accuracy score:0.9255350703279891
F1 Score:0.8920619116582187
---------------------------------------------------------------
Confusion Matrix:
[[39576  2929]
 [ 1841 19711]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 192.08896255493164 seconds

[2022-03-19 16:17:05.083408]
===============================================================



[95]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.95      0.93      0.94     42531
           1       0.87      0.91      0.89     21537

    accuracy                           0.93     64068
   macro avg       0.91      0.92      0.92     64068
weighted avg       0.93      0.93      0.93     64068

---------------------------------------------------------------
Precision score:0.9262346257101829
Recall score:0.9119190230765659
Accuracy score:0.9262346257101829
F1 Score:0.8926055537881198
---------------------------------------------------------------
Confusion Matrix:
[[39702  2829]
 [ 1897 19640]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 189.9844081401825 seconds

[2022-03-19 16:21:05.558678]
===============================================================



[96]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.94     42532
           1       0.87      0.92      0.89     21517

    accuracy                           0.93     64049
   macro avg       0.91      0.92      0.92     64049
weighted avg       0.93      0.93      0.93     64049

---------------------------------------------------------------
Precision score:0.9271183000515231
Recall score:0.9162987405307431
Accuracy score:0.9271183000515231
F1 Score:0.8941496598639456
---------------------------------------------------------------
Confusion Matrix:
[[39665  2867]
 [ 1801 19716]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 199.50028157234192 seconds

[2022-03-19 16:25:14.645864]
===============================================================



[97]====[Optimum Logistic_Regression Results & Hyperparameters(fc_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.96      0.93      0.95     42455
           1       0.87      0.92      0.90     21568

    accuracy                           0.93     64023
   macro avg       0.92      0.93      0.92     64023
weighted avg       0.93      0.93      0.93     64023

---------------------------------------------------------------
Precision score:0.9282132983459069
Recall score:0.9182585311572701
Accuracy score:0.9282132983459069
F1 Score:0.896032212821789
---------------------------------------------------------------
Confusion Matrix:
[[39622  2833]
 [ 1763 19805]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 197.49372553825378 seconds

[2022-03-19 16:29:23.052610]
===============================================================



[98]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64803
           1       0.87      0.92      0.89     51533

    accuracy                           0.90    116336
   macro avg       0.90      0.90      0.90    116336
weighted avg       0.90      0.90      0.90    116336

---------------------------------------------------------------
Precision score:0.9013461009489754
Recall score:0.9193720528593329
Accuracy score:0.9013461009489754
F1 Score:0.8919638906930992
---------------------------------------------------------------
Confusion Matrix:
[[57481  7322]
 [ 4155 47378]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 282.9764964580536 seconds

[2022-03-19 16:34:33.621990]
===============================================================



[99]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64795
           1       0.87      0.92      0.89     51664

    accuracy                           0.90    116459
   macro avg       0.90      0.90      0.90    116459
weighted avg       0.90      0.90      0.90    116459

---------------------------------------------------------------
Precision score:0.901287148266772
Recall score:0.9202152369154537
Accuracy score:0.901287148266772
F1 Score:0.8921373616063051
---------------------------------------------------------------
Confusion Matrix:
[[57421  7374]
 [ 4122 47542]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 284.9291784763336 seconds

[2022-03-19 16:39:44.391455]
===============================================================



[100]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64715
           1       0.87      0.91      0.89     51559

    accuracy                           0.90    116274
   macro avg       0.90      0.90      0.90    116274
weighted avg       0.90      0.90      0.90    116274

---------------------------------------------------------------
Precision score:0.9003732562739736
Recall score:0.9149905933008786
Accuracy score:0.9003732562739736
F1 Score:0.8906509590696269
---------------------------------------------------------------
Confusion Matrix:
[[57514  7201]
 [ 4383 47176]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 283.3091948032379 seconds

[2022-03-19 16:44:54.910345]
===============================================================



[101]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_none)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64763
           1       0.87      0.91      0.89     51552

    accuracy                           0.90    116315
   macro avg       0.90      0.90      0.90    116315
weighted avg       0.90      0.90      0.90    116315

---------------------------------------------------------------
Precision score:0.8994970554098783
Recall score:0.9138151769087524
Accuracy score:0.8994970554098783
F1 Score:0.8896211806473543
---------------------------------------------------------------
Confusion Matrix:
[[57516  7247]
 [ 4443 47109]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 282.11775612831116 seconds

[2022-03-19 16:50:03.324117]
===============================================================



[102]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64816
           1       0.87      0.91      0.89     51633

    accuracy                           0.90    116449
   macro avg       0.90      0.90      0.90    116449
weighted avg       0.90      0.90      0.90    116449

---------------------------------------------------------------
Precision score:0.9002481773136738
Recall score:0.9138341758177909
Accuracy score:0.9002481773136738
F1 Score:0.8903985507246377
---------------------------------------------------------------
Confusion Matrix:
[[57649  7167]
 [ 4449 47184]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 237.8116636276245 seconds

[2022-03-19 16:54:27.766625]
===============================================================



[103]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64771
           1       0.87      0.92      0.89     51713

    accuracy                           0.90    116484
   macro avg       0.90      0.90      0.90    116484
weighted avg       0.90      0.90      0.90    116484

---------------------------------------------------------------
Precision score:0.900767487380241
Recall score:0.917796298803009
Accuracy score:0.900767487380241
F1 Score:0.8914474610970765
---------------------------------------------------------------
Confusion Matrix:
[[57463  7308]
 [ 4251 47462]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 237.5632586479187 seconds

[2022-03-19 16:58:50.877946]
===============================================================



[104]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64901
           1       0.87      0.91      0.89     51526

    accuracy                           0.90    116427
   macro avg       0.90      0.90      0.90    116427
weighted avg       0.90      0.90      0.90    116427

---------------------------------------------------------------
Precision score:0.8988894328635111
Recall score:0.912063812444203
Accuracy score:0.8988894328635111
F1 Score:0.8886934815907415
---------------------------------------------------------------
Confusion Matrix:
[[57660  7241]
 [ 4531 46995]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 238.68632125854492 seconds

[2022-03-19 17:03:15.832589]
===============================================================



[105]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_std)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64805
           1       0.87      0.91      0.89     51547

    accuracy                           0.90    116352
   macro avg       0.90      0.90      0.90    116352
weighted avg       0.90      0.90      0.90    116352

---------------------------------------------------------------
Precision score:0.8998813943894389
Recall score:0.913709818224145
Accuracy score:0.8998813943894389
F1 Score:0.8899449204984554
---------------------------------------------------------------
Confusion Matrix:
[[57604  7201]
 [ 4448 47099]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 236.13616681098938 seconds

[2022-03-19 17:07:38.971996]
===============================================================



[106]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.92      0.89      0.91     64901
           1       0.87      0.90      0.88     51475

    accuracy                           0.90    116376
   macro avg       0.89      0.90      0.90    116376
weighted avg       0.90      0.90      0.90    116376

---------------------------------------------------------------
Precision score:0.8961727503952706
Recall score:0.8989995143273434
Accuracy score:0.8961727503952706
F1 Score:0.88452238734649
---------------------------------------------------------------
Confusion Matrix:
[[58017  6884]
 [ 5199 46276]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 270.09804248809814 seconds

[2022-03-19 17:12:34.973297]
===============================================================



[107]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.92      0.89      0.91     64918
           1       0.87      0.91      0.89     51627

    accuracy                           0.90    116545
   macro avg       0.90      0.90      0.90    116545
weighted avg       0.90      0.90      0.90    116545

---------------------------------------------------------------
Precision score:0.8984255008794886
Recall score:0.9074902667209018
Accuracy score:0.8984255008794886
F1 Score:0.8878339965889711
---------------------------------------------------------------
Confusion Matrix:
[[57856  7062]
 [ 4776 46851]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 271.13978242874146 seconds

[2022-03-19 17:17:33.692586]
===============================================================



[108]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64830
           1       0.87      0.92      0.89     51649

    accuracy                           0.90    116479
   macro avg       0.90      0.90      0.90    116479
weighted avg       0.90      0.90      0.90    116479

---------------------------------------------------------------
Precision score:0.9006258638896282
Recall score:0.9175976301574087
Accuracy score:0.9006258638896282
F1 Score:0.8911725162418556
---------------------------------------------------------------
Confusion Matrix:
[[57511  7319]
 [ 4256 47393]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 272.9623773097992 seconds

[2022-03-19 17:22:33.605983]
===============================================================



[109]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64749
           1       0.87      0.91      0.89     51655

    accuracy                           0.90    116404
   macro avg       0.90      0.90      0.90    116404
weighted avg       0.90      0.90      0.90    116404

---------------------------------------------------------------
Precision score:0.8996855778151953
Recall score:0.909418255735166
Accuracy score:0.8996855778151953
F1 Score:0.8894527071164169
---------------------------------------------------------------
Confusion Matrix:
[[57751  6998]
 [ 4679 46976]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 281.0817000865936 seconds

[2022-03-19 17:27:43.197303]
===============================================================



[110]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64812
           1       0.87      0.91      0.89     51670

    accuracy                           0.90    116482
   macro avg       0.90      0.90      0.90    116482
weighted avg       0.90      0.90      0.90    116482

---------------------------------------------------------------
Precision score:0.9003107776308786
Recall score:0.9139732920456745
Accuracy score:0.9003107776308786
F1 Score:0.8905168674925986
---------------------------------------------------------------
Confusion Matrix:
[[57645  7167]
 [ 4445 47225]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 254.90221905708313 seconds

[2022-03-19 17:32:24.846478]
===============================================================



[111]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64836
           1       0.87      0.91      0.89     51475

    accuracy                           0.90    116311
   macro avg       0.90      0.90      0.90    116311
weighted avg       0.90      0.90      0.90    116311

---------------------------------------------------------------
Precision score:0.8980320004126867
Recall score:0.9113161728994658
Accuracy score:0.8980320004126867
F1 Score:0.8877744133232399
---------------------------------------------------------------
Confusion Matrix:
[[57541  7295]
 [ 4565 46910]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 249.5464470386505 seconds

[2022-03-19 17:37:02.614796]
===============================================================



[112]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64863
           1       0.87      0.91      0.89     51486

    accuracy                           0.90    116349
   macro avg       0.90      0.90      0.90    116349
weighted avg       0.90      0.90      0.90    116349

---------------------------------------------------------------
Precision score:0.8995092351459832
Recall score:0.9125781765916948
Accuracy score:0.8995092351459832
F1 Score:0.889345270769056
---------------------------------------------------------------
Confusion Matrix:
[[57672  7191]
 [ 4501 46985]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 255.97941851615906 seconds

[2022-03-19 17:41:46.560225]
===============================================================



[113]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-10)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64802
           1       0.87      0.91      0.89     51637

    accuracy                           0.90    116439
   macro avg       0.90      0.90      0.90    116439
weighted avg       0.90      0.90      0.90    116439

---------------------------------------------------------------
Precision score:0.8983330327467601
Recall score:0.912001084493677
Accuracy score:0.8983330327467601
F1 Score:0.8883460348600318
---------------------------------------------------------------
Confusion Matrix:
[[57508  7294]
 [ 4544 47093]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 257.8614273071289 seconds

[2022-03-19 17:46:32.538917]
===============================================================



[114]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64770
           1       0.86      0.92      0.89     51616

    accuracy                           0.90    116386
   macro avg       0.90      0.90      0.90    116386
weighted avg       0.90      0.90      0.90    116386

---------------------------------------------------------------
Precision score:0.8998762737786332
Recall score:0.9176999380037197
Accuracy score:0.8998762737786332
F1 Score:0.8904679995112276
---------------------------------------------------------------
Confusion Matrix:
[[57365  7405]
 [ 4248 47368]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 273.2597403526306 seconds

[2022-03-19 17:51:34.030585]
===============================================================



[115]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.88      0.91     64887
           1       0.86      0.92      0.89     51568

    accuracy                           0.90    116455
   macro avg       0.90      0.90      0.90    116455
weighted avg       0.90      0.90      0.90    116455

---------------------------------------------------------------
Precision score:0.9004164698810699
Recall score:0.9213271796462923
Accuracy score:0.9004164698810699
F1 Score:0.8912295181909416
---------------------------------------------------------------
Confusion Matrix:
[[57347  7540]
 [ 4057 47511]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 276.5607645511627 seconds

[2022-03-19 17:56:38.957238]
===============================================================



[116]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64783
           1       0.87      0.91      0.89     51619

    accuracy                           0.90    116402
   macro avg       0.90      0.90      0.90    116402
weighted avg       0.90      0.90      0.90    116402

---------------------------------------------------------------
Precision score:0.8996838542293087
Recall score:0.9114085898603228
Accuracy score:0.8996838542293087
F1 Score:0.8895990318524332
---------------------------------------------------------------
Confusion Matrix:
[[57679  7104]
 [ 4573 47046]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'sag', 'lgr__tol': 0.02, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 271.2169826030731 seconds

[2022-03-19 18:01:37.264124]
===============================================================



[117]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-100)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64854
           1       0.87      0.92      0.89     51468

    accuracy                           0.90    116322
   macro avg       0.90      0.90      0.90    116322
weighted avg       0.90      0.90      0.90    116322

---------------------------------------------------------------
Precision score:0.9010849194477399
Recall score:0.9165306598274656
Accuracy score:0.9010849194477399
F1 Score:0.8912990080302314
---------------------------------------------------------------
Confusion Matrix:
[[57644  7210]
 [ 4296 47172]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 50, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 272.11093854904175 seconds

[2022-03-19 18:06:36.076687]
===============================================================



[118]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64849
           1       0.87      0.93      0.90     51587

    accuracy                           0.90    116436
   macro avg       0.90      0.91      0.90    116436
weighted avg       0.91      0.90      0.91    116436

---------------------------------------------------------------
Precision score:0.9048060737229036
Recall score:0.9258727974102002
Accuracy score:0.9048060737229036
F1 Score:0.8960322671419191
---------------------------------------------------------------
Confusion Matrix:
[[57589  7260]
 [ 3824 47763]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 380.0305321216583 seconds

[2022-03-19 18:13:22.753928]
===============================================================



[119]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64802
           1       0.87      0.92      0.90     51636

    accuracy                           0.91    116438
   macro avg       0.90      0.91      0.90    116438
weighted avg       0.91      0.91      0.91    116438

---------------------------------------------------------------
Precision score:0.9055033580102716
Recall score:0.923367418080409
Accuracy score:0.9055033580102716
F1 Score:0.8965504273182839
---------------------------------------------------------------
Confusion Matrix:
[[57756  7046]
 [ 3957 47679]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'auto', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 377.0814516544342 seconds

[2022-03-19 18:20:07.537282]
===============================================================



[120]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     64680
           1       0.87      0.92      0.90     51707

    accuracy                           0.90    116387
   macro avg       0.90      0.91      0.90    116387
weighted avg       0.91      0.90      0.90    116387

---------------------------------------------------------------
Precision score:0.9047230360779125
Recall score:0.9205910224921191
Accuracy score:0.9047230360779125
F1 Score:0.8956731990478969
---------------------------------------------------------------
Confusion Matrix:
[[57697  6983]
 [ 4106 47601]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.001, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'multinomial', 'lgr__penalty': 'none', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 378.33843660354614 seconds

[2022-03-19 18:26:52.426212]
===============================================================



[121]====[Optimum Logistic_Regression Results & Hyperparameters(lr_valid_lb_mm_0-1000)]====

Parameter Grid Used:
{'C': [0.001, 0.002], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [50, 60], 'multi_class': ['auto', 'multinomial'], 'penalty': ['l2', 'none'], 'random_state': [42], 'solver': ['lbfgs', 'sag'], 'tol': [0.01, 0.02], 'verbose': [0], 'warm_start': [True]}

--------------------[Classification Report]--------------------
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     64744
           1       0.87      0.93      0.90     51599

    accuracy                           0.91    116343
   macro avg       0.90      0.91      0.90    116343
weighted avg       0.91      0.91      0.91    116343

---------------------------------------------------------------
Precision score:0.9054176014027487
Recall score:0.9274598344929166
Accuracy score:0.9054176014027487
F1 Score:0.8968851905993479
---------------------------------------------------------------
Confusion Matrix:
[[57483  7261]
 [ 3743 47856]]
---------------------------------------------------------------
Optimal Parameters:
{'lgr__C': 0.002, 'lgr__class_weight': None, 'lgr__dual': False, 'lgr__fit_intercept': True, 'lgr__intercept_scaling': 1, 'lgr__l1_ratio': None, 'lgr__max_iter': 60, 'lgr__multi_class': 'auto', 'lgr__penalty': 'l2', 'lgr__random_state': 42, 'lgr__solver': 'lbfgs', 'lgr__tol': 0.01, 'lgr__verbose': 0, 'lgr__warm_start': True}
---------------------------------------------------------------
Runtime: 378.17267060279846 seconds

[2022-03-19 18:33:40.224448]
===============================================================